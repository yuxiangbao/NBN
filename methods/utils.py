from collections import defaultdict
import pickle
import matplotlib; matplotlib.use("Agg")
import matplotlib.pyplot as plt
import numpy as np
import torch
import math
import torch.distributed as dist
from torchvision.utils import save_image

import warnings
import os

import pdb

def save_pickle(file, data):
    with open(file, 'wb') as f:
        pickle.dump(data, f)

def load_pickle(file):
    with open(file, 'rb') as f:
        return pickle.load(f)

def compute_confusion_matrix(actual, predicted):
   # extract the different classes
    classes = np.unique(actual)

    # initialize the confusion matrix
    confmat = np.zeros((len(classes), len(classes)))

    # loop across the different combinations of actual / predicted classes
    for i in range(len(classes)):
        for j in range(len(classes)):

           # count the number of instances in each combination of actual / predicted classes
           confmat[i, j] = np.sum((actual == classes[i]) & (predicted == classes[j]))

    return confmat

def entropy(logits):
    return -(logits.softmax(dim=1) * logits.log_softmax(dim=1)).sum(1)

def pnorm(model, tau=0):
    weights = model.module.weight
    normB = torch.norm(weights, p=2, dim=1)
    ws = weights.clone()
    # pdb.set_trace()
    ws =  ws/torch.pow(normB.unsqueeze(1), tau)
    model_dict = model.module.state_dict()
    model_dict["weight"].copy_(ws) 

    return ws

def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    # type: (Tensor, float, float, float, float) -> Tensor
    r"""Fills the input Tensor with values drawn from a truncated
    normal distribution. The values are effectively drawn from the
    normal distribution :math:`\mathcal{N}(\text{mean}, \text{std}^2)`
    with values outside :math:`[a, b]` redrawn until they are within
    the bounds. The method used for generating the random values works
    best when :math:`a \leq \text{mean} \leq b`.
    Args:
        tensor: an n-dimensional `torch.Tensor`
        mean: the mean of the normal distribution
        std: the standard deviation of the normal distribution
        a: the minimum cutoff value
        b: the maximum cutoff value
    Examples:
        >>> w = torch.empty(3, 5)
        >>> nn.init.trunc_normal_(w)
    """
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)

def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor

def get_task_content(train_data, many_shot_thr=100, low_shot_thr=20):
    if isinstance(train_data, np.ndarray):
        training_labels = np.array(train_data).astype(int)
    else:
        training_labels = np.array(train_data.dataset.labels).astype(int)

    _, freq = np.unique(training_labels, return_counts=True)
    freq = freq/freq.sum()

    task_content = defaultdict(list)
    for l in np.unique(training_labels):
        num = len(training_labels[training_labels == l])
        if num<low_shot_thr:
            task_content["low"].append(l)
        elif num>many_shot_thr:
            task_content["many"].append(l)
        else:
            task_content["median"].append(l)

    for k, v in task_content.items():
        task_content[k] = np.array(v, dtype=np.int)

    return task_content, len(np.unique(training_labels)), freq

def target2task(target, task_content, task_strs, num_classes):
    task = torch.zeros_like(target)
    for task_id, task_str in enumerate(task_strs):
        classes = task_content[task_str]  
        task_vec = torch.zeros(num_classes, dtype=torch.bool, device=target.device)
        task_vec[classes] = 1
        index = task_vec[target] 
        task[index] = task_id
    return task

def t2t(target, task_content, task_strs, num_classes):
    task = torch.zeros_like(num_classes)
    for task_id, task_str in enumerate(task_strs):
        classes = task_content[task_str]  
        task[classes] = task_id
    return task[target]

def get_adv_prob_per_sample(y, freq, adv_prob_ub):
    cls_freq_per_sample = freq[y.cpu().numpy()] # get the freq of each sample's class
    adv_prob_per_sample = cls_freq_per_sample / freq.max() * adv_prob_ub # linear transform
    return adv_prob_per_sample

def train_fc_only(model):
    for n, p in model.named_parameters():
        p.requires_grad = False
        if "fc" in n:
            p.requires_grad = True
    model = tune_scale(model)
    return model

def tune_scale(model):
    for n, p in model.named_parameters():
        if "scale" in n:
            p.requires_grad = True

    return model

def freeze_model(model):
    for n, p in model.named_parameters():
        p.requires_grad = False

    return model

def choose_task(task, predicted_task, k):
    if k==-1:
        return task, predicted_task
    index = task==k
    return task[index], predicted_task[index]

def update(config, args):
    for key, val in config.items():
        if not getattr(args, key, None):
                setattr(args, key, val)
    return args

@torch.no_grad()
def save_adv(x_adv, epoch, iter, log_dir, distributed=False, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], **kwargs):
    if not distributed or (distributed and dist.get_rank()==0):
        save_dir = os.path.join(log_dir, f"adv_in_epoch_{epoch}")
        if not os.path.exists(save_dir):
            os.mkdir(save_dir)
        if iter % 100 == 0:
            x_adv = x_adv[:5] if len(x_adv)>5 else x_adv
            mean, std = torch.tensor(mean, device=x_adv.device), torch.tensor(std, device=x_adv.device)
            x_adv = x_adv * std.view(-1, 1, 1) + mean.view(-1, 1, 1)
            for i in range(len(x_adv)):
                save_image(x_adv[i], os.path.join(save_dir, "{}.jpg".format(iter//100*5+i)), normalize=True)
    return
 
def save_plot_atk_tgts(attack_tgts, tgts, freq, epoch, args):
    if not attack_tgts:
        return
        
    if args.distributed:
        dist.barrier()
        attack_tgts.all_reduce()
        tgts.all_reduce()

    if not args.multiprocessing_distributed or (args.multiprocessing_distributed
            and args.rank == 0):
        num = attack_tgts.num.detach().cpu().numpy()
        ratio = attack_tgts.ratio.detach().cpu().numpy()
        ratio_tgts = tgts.ratio.detach().cpu().numpy()
        save_path = os.path.join(args.log_dir, f"attack_targets_ratio_in_{epoch}_epoch.pkl")
        save_pickle(save_path, dict(ratio=ratio, ratio_tgts=ratio_tgts, freq=freq))
        plot_ratio(ratio, epoch, freq, args.log_dir)
        plot_ratio_tgts(ratio_tgts, epoch, freq, args.log_dir)
    return

def plot_ratio(ratio, epoch, freq, save_dir):
    print('* * * Drawing the attack targets ratio * * *')
    num_classes = len(ratio)
    x = np.arange(num_classes)
    index = np.argsort(freq)
    index = index[::-1]  # decreasing order
    fig = plt.figure(figsize=(7,9))
    ax1 = fig.add_subplot(2,1,1)
    ax1.set_xlabel('class')
    ax1.set_ylabel('ratio')
    ax1.set_title(f"The Ratio of Attack Targets in {epoch} epoch")
    ax1.bar(x, ratio[index])

    ax2 = fig.add_subplot(2,1,2)
    ax2.set_xlabel('class')
    ax2.set_ylabel('frequency')
    ax2.set_title(f"Frequency of Classes")
    ax2.bar(x, freq[index])
    
    _savefig(os.path.join(save_dir, f"Ratio_in_{epoch}_epoch.jpg"), dpi=300)
    return

def plot_ratio_tgts(ratio, epoch, freq, save_dir):
    print('* * * Drawing the attack targets ratio * * *')
    num_classes = len(ratio)
    x = np.arange(num_classes)
    index = np.argsort(freq)
    index = index[::-1]  # decreasing order
    fig = plt.figure(figsize=(7,9))
    ax1 = fig.add_subplot(2,1,1)
    ax1.set_xlabel('class')
    ax1.set_ylabel('ratio')
    ax1.set_title(f"The Ratio of Targets in {epoch} epoch")
    ax1.bar(x, ratio[index])

    ax2 = fig.add_subplot(2,1,2)
    ax2.set_xlabel('class')
    ax2.set_ylabel('frequency')
    ax2.set_title(f"Frequency of Classes")
    ax2.bar(x, freq[index])
    
    _savefig(os.path.join(save_dir, f" Targets_ratio_in_{epoch}_epoch.jpg"), dpi=300)
    return

def plot_grad_norm(grad_norm, save_dir="./", window_size=150):
    grad_norm = np.transpose(np.array(grad_norm))
    grad_norm_avg = []
    for i in range(grad_norm.shape[1]):
        grad_norm_avg.append(np.convolve(grad_norm[:, i], 
                                    np.ones(window_size)/window_size, 
                                    mode='valid')) 
    grad_norm = np.stack(grad_norm_avg, axis=1)
    x = np.arange(grad_norm.shape[0])
    fig = plt.figure(figsize=(7,5))
    ax1 = fig.add_subplot(1,1,1)
    ax1.plot(x, grad_norm)
    ax1.set_xlabel('iterations')
    ax1.set_ylabel('gradient norm')
    ax1.set_title('Gradient Norm of the Last Module of Each Layer')
    ax1.legend(["layer1", "layer2", "layer3", "layer4", "fc"], loc='upper left')
    _savefig(os.path.join(save_dir, 'grad_norm.jpg'), dpi=300)

def plot_scale_factor(scale_factor, save_dir="./", window_size=150):
    scale_factor = np.array(scale_factor)
    x = np.arange(scale_factor.shape[1])
    fig = plt.figure(figsize=(7, 5))
    ax1 = fig.add_subplot(1,1,1)
    ax1.plot(x, np.transpose(scale_factor))
    ax1.set_xlabel('iterations')
    ax1.set_ylabel('scale factor')
    ax1.set_title('Scale Factor in the Training Process')
    ax1.legend(["layer1", "layer2", "layer3", "layer4"])
    _savefig(os.path.join(save_dir, 'scale_factor.jpg'), dpi=300)

def plot_val_acc(val_acc, save_dir="./", window_size=150):
    val_acc = np.array(val_acc)
    x = np.arange(val_acc.shape[0])
    fig = plt.figure(figsize=(7, 5))
    ax1 = fig.add_subplot(1,1,1)
    ax1.plot(x, val_acc)
    ax1.set_xlabel('epoch')
    ax1.set_ylabel('Val Acc')
    ax1.set_title('Accuracy on the Validation Set in the Training Process')
    ax1.legend(["All", "Tail", "Medium", "Head"])
    _savefig(os.path.join(save_dir, 'val_acc.jpg'), dpi=300)



def _savefig(name='./image.jpg', dpi=300):
    plt.savefig(name, dpi=dpi)
    print('Image saved at {}'.format(name))

